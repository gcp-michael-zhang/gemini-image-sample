{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZcWHMP-n5hQ"
      },
      "source": [
        "# Gemini 2.5 Flash Image Generation using REST API\n",
        "\n",
        "This notebook demonstrates how to use Gemini 2.5 Flash Image generation capabilities through REST API calls instead of the Google Gen AI SDK.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Gemini 2.5 Flash Image is a powerful, generalist multimodal model that offers state-of-the-art image generation and conversational image editing capabilities. This enables you to converse with Gemini and create or edit images with interwoven text.\n",
        "\n",
        "In this tutorial, you'll learn how to use Gemini 2.5 Flash Image in Vertex AI using REST API calls to try out the following scenarios:\n",
        "  - Image generation:\n",
        "    - Text-to-image generation\n",
        "    - Interleaved image and text sequences\n",
        "  - Image editing:\n",
        "    - Image-to-image with subject customization and style transfer\n",
        "    - Multi-turn image editing with localization\n",
        "    - Editing with multiple reference images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u1pCQO1n5hR"
      },
      "source": [
        "## Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeKS-UwVn5hR"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install --upgrade --quiet requests pillow matplotlib ipython base64 google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uSDW0FHn5hR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image as PIL_Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import Image, Markdown, display\n",
        "import uuid\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import base64\n",
        "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
        "from google.oauth2 import service_account\n",
        "import os\n",
        "import vertexai\n",
        "from google.cloud import storage\n",
        "import json\n",
        "from google.cloud.aiplatform_v1beta1.types import (\n",
        "    content as gapic_content_types,\n",
        ")\n",
        "import requests\n",
        "from google.auth.transport.requests import Request\n",
        "import time\n",
        "from PIL import Image\n",
        "import logging\n",
        "import google\n",
        "import base64\n",
        "\n",
        "import vertexai.generative_models as generative_models\n",
        "\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "from google.cloud import storage\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "from diffusers.utils import make_image_grid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "creds, PROJECT = google.auth.default()\n",
        "auth_req = google.auth.transport.requests.Request()\n",
        "creds.refresh(auth_req)"
      ],
      "metadata": {
        "id": "CiFWcZKFoGck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si28Vo7mn5hR"
      },
      "source": [
        "### Understanding HTTP Requests with Python Requests Library\n",
        "\n",
        "This notebook demonstrates how to use the **`requests`** library to make HTTP calls to the Gemini 2.5 Flash Image API. The `requests` library is the standard Python library for making HTTP requests and provides a simple, elegant API for interacting with REST endpoints.\n",
        "\n",
        "#### Key `requests` Features Used:\n",
        "- **`requests.get()`**: Download images from URLs  \n",
        "- **`requests.post()`**: Send JSON payloads to the Gemini API\n",
        "- **Headers Management**: Set Content-Type and authentication headers\n",
        "- **Error Handling**: Check HTTP status codes and handle exceptions\n",
        "- **JSON Handling**: Automatic JSON encoding/decoding\n",
        "- **Timeout Support**: Prevent hanging requests\n",
        "- **Retry Logic**: Handle rate limiting and transient errors\n",
        "\n",
        "#### HTTP Request Structure:\n",
        "```python\n",
        "# Basic pattern used throughout this notebook:\n",
        "response = requests.post(\n",
        "    url=API_ENDPOINT,\n",
        "    headers={'Content-Type': 'application/json'},\n",
        "    json=payload,\n",
        "    timeout=300\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwuiQ52-n5hS"
      },
      "source": [
        "### Set API Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UN300wfn5hS"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "API_ENDPOINT = \"aiplatform.googleapis.com\"\n",
        "MODEL_ID = \"gemini-2.5-flash-image-preview\"\n",
        "GENERATE_CONTENT_API = \"generateContent\"\n",
        "PROJECT_ID=\"frankie1-422709\"\n",
        "\n",
        "# Base URL for API calls\n",
        "BASE_URL = f\"https://{API_ENDPOINT}/v1/projects/{PROJECT_ID}/locations/global/publishers/google/models/{MODEL_ID}:{GENERATE_CONTENT_API}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gafrG23_n5hS"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaZ4_bBcn5hS"
      },
      "outputs": [],
      "source": [
        "def encode_image_to_base64(image_path):\n",
        "    \"\"\"Encode local image file to base64 string\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "def download_image(url, filename):\n",
        "    \"\"\"Download image from URL and save locally\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        return filename\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download image: {response.status_code}\")\n",
        "\n",
        "def display_image_from_base64(base64_data, width=400):\n",
        "    \"\"\"Display image from base64 data\"\"\"\n",
        "    image_data = base64.b64decode(base64_data)\n",
        "    display(Image.open(io.BytesIO(image_data)))\n",
        "\n",
        "def create_request_payload(contents, temperature=1, max_output_tokens=32768):\n",
        "    \"\"\"Create the request payload for Gemini API\"\"\"\n",
        "    return {\n",
        "        \"contents\": contents,\n",
        "        \"generation_config\": {\n",
        "            \"temperature\": temperature,\n",
        "            \"max_output_tokens\": max_output_tokens,\n",
        "            \"response_modalities\": [\"TEXT\", \"IMAGE\"],\n",
        "            \"topP\": 0.95\n",
        "        },\n",
        "        \"safetySettings\": [\n",
        "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"OFF\"},\n",
        "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"OFF\"},\n",
        "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"OFF\"},\n",
        "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"OFF\"}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "def send_gemini_request(payload):\n",
        "    \"\"\"Send request to Gemini API and return response\"\"\"\n",
        "    request = Request()\n",
        "    creds.refresh(request=request)\n",
        "    access_token = creds.token\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {access_token}',\n",
        "        'Content-Type': 'application/json;charset=utf-8',\n",
        "    }\n",
        "\n",
        "    response = requests.post(BASE_URL, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(f\"API request failed: {response.status_code} - {response.text}\")\n",
        "\n",
        "def process_response(response_data):\n",
        "    \"\"\"Process and display the response from Gemini API\"\"\"\n",
        "    # Handle streaming response format\n",
        "    if isinstance(response_data, list):\n",
        "        # For streaming responses, combine all parts\n",
        "        all_parts = []\n",
        "        for item in response_data:\n",
        "            if 'candidates' in item and len(item['candidates']) > 0:\n",
        "                if 'content' in item['candidates'][0] and 'parts' in item['candidates'][0]['content']:\n",
        "                    all_parts.extend(item['candidates'][0]['content']['parts'])\n",
        "    else:\n",
        "        # For non-streaming responses\n",
        "        if 'candidates' in response_data and len(response_data['candidates']) > 0:\n",
        "            if 'content' in response_data['candidates'][0] and 'parts' in response_data['candidates'][0]['content']:\n",
        "                all_parts = response_data['candidates'][0]['content']['parts']\n",
        "            else:\n",
        "                all_parts = []\n",
        "        else:\n",
        "            all_parts = []\n",
        "\n",
        "    print(all_parts)\n",
        "    # Display text and images\n",
        "    for part in all_parts:\n",
        "        if 'text' in part:\n",
        "            display(Markdown(part['text']))\n",
        "        elif 'inlineData' in part:\n",
        "            if 'data' in part['inlineData']:\n",
        "                display_image_from_base64(part['inlineData']['data'])\n",
        "\n",
        "    return all_parts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQV2cQjzn5hS"
      },
      "source": [
        "## Image Generation\n",
        "\n",
        "First, you'll send text prompts to Gemini 2.5 Flash Image describing the images you'd like to generate.\n",
        "\n",
        "### Text to Image\n",
        "\n",
        "In the cell below, you'll create a request payload and call the Gemini API with the following configuration:\n",
        "- `responseModalities`: To generate an image, you must include `IMAGE` in the `responseModalities` list. Note that `IMAGE` cannot be the only value specified; it must be accompanied by `TEXT`.\n",
        "- `safetySettings`: Configuration for content safety filtering\n",
        "\n",
        "All generated images include a SynthID watermark, which can be verified via the Media Studio in Vertex AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Ow5eDpn5hS"
      },
      "outputs": [],
      "source": [
        "# Text to image generation example\n",
        "text_prompt = \"a cartoon infographic on flying sneakers\"\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\"text\": text_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(f\"Generating image for prompt: '{text_prompt}'  \")\n",
        "print(f\"{payload}\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    process_response(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GawYtLon5hS"
      },
      "source": [
        "### Text to Image and Text (Interleaved Sequences)\n",
        "\n",
        "In addition to generating images, Gemini can also create interleaved sequences of images and text.\n",
        "\n",
        "For example, you could ask the model to generate a recipe for banana bread with images showing different stages of the cooking process. Or, you could ask the model to generate images of different wildflowers with accompanying titles and descriptions.\n",
        "\n",
        "Let's try out the interleaved text and image functionality by prompting Gemini 2.5 Flash Image to create a tutorial for assembling a peanut butter and jelly sandwich."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De9LSVhOn5hS"
      },
      "outputs": [],
      "source": [
        "# Interleaved text and image generation\n",
        "tutorial_prompt = \"Create a tutorial explaining how to make a peanut butter and jelly sandwich in three easy steps. For each step, provide a title with the number of the step, an explanation, and also generate an image to illustrate the content. Label each image with the step number but no other words.\"\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\"text\": tutorial_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(f\"Generating tutorial with interleaved text and images...\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    process_response(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVgQykIfn5hS"
      },
      "source": [
        "## Image Editing\n",
        "\n",
        "Gemini 2.5 Flash Image can generate image-to-image outputs from multiple reference images. This is useful for tasks like ensuring character consistency, generating logos, transferring styles, and inserting or removing objects.\n",
        "\n",
        "### Subject Customization\n",
        "\n",
        "Let's try out a subject customization example by asking Gemini 2.5 Flash Image to create an image of a dog in both a pencil sketch and watercolor style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32-Ao8q7n5hS"
      },
      "outputs": [],
      "source": [
        "# Download the dog image\n",
        "dog_image_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/dog-1.jpg\"\n",
        "dog_image_path = \"dog-1.jpg\"\n",
        "\n",
        "try:\n",
        "    download_image(dog_image_url, dog_image_path)\n",
        "    print(f\"Downloaded dog image to {dog_image_path}\")\n",
        "\n",
        "    # Display the downloaded image\n",
        "    img = mpimg.imread(dog_image_path)\n",
        "    plt.figure(figsize=(6, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title('Original Dog Image')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading image: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moj5Fy9in5hS"
      },
      "outputs": [],
      "source": [
        "# Subject customization with the dog image\n",
        "dog_base64 = encode_image_to_base64(dog_image_path)\n",
        "\n",
        "customization_prompt = \"Create a pencil sketch image of this dog wearing a cowboy hat in a western-themed setting. Generate another image of this dog in a watercolor style floating down a river on a paddle board.\"\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\n",
        "                \"inlineData\": {\n",
        "                    \"mimeType\": \"image/jpeg\",\n",
        "                    \"data\": dog_base64\n",
        "                }\n",
        "            },\n",
        "            {\"text\": customization_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(\"Generating customized images of the dog...\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    process_response(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpfSqvTnn5hS"
      },
      "source": [
        "### Style Transfer\n",
        "\n",
        "In this next example, you'll use the style from a living room to reimagine a kitchen in the same style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrxcCyiIn5hT"
      },
      "outputs": [],
      "source": [
        "# Download the living room image\n",
        "living_room_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/living-room.png\"\n",
        "living_room_path = \"living-room.png\"\n",
        "\n",
        "try:\n",
        "    download_image(living_room_url, living_room_path)\n",
        "    print(f\"Downloaded living room image to {living_room_path}\")\n",
        "\n",
        "    # Display the downloaded image\n",
        "    img = mpimg.imread(living_room_path)\n",
        "    plt.figure(figsize=(6, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title('Living Room Style Reference')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading image: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGyu01gjn5hT"
      },
      "outputs": [],
      "source": [
        "# Style transfer example\n",
        "living_room_base64 = encode_image_to_base64(living_room_path)\n",
        "\n",
        "style_transfer_prompt = \"Using the concepts, colors, and themes from this living room generate a kitchen and dining room with the same aesthetic.\"\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\n",
        "                \"inlineData\": {\n",
        "                    \"mimeType\": \"image/png\",\n",
        "                    \"data\": living_room_base64\n",
        "                }\n",
        "            },\n",
        "            {\"text\": style_transfer_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(\"Generating kitchen with living room style transfer...\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    process_response(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9qdNULfn5hT"
      },
      "source": [
        "### Multi-turn Image Editing\n",
        "\n",
        "In this next section, you supply a starting image and iteratively alter certain aspects of the image by chatting with Gemini 2.5 Flash Image.\n",
        "\n",
        "For multi-turn conversations, we'll simulate the chat functionality by maintaining conversation history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRHGUSzEn5hT"
      },
      "outputs": [],
      "source": [
        "# Display the perfume bottle image that we'll be editing\n",
        "perfume_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/perfume.jpg\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(perfume_url)\n",
        "    if response.status_code == 200:\n",
        "        perfume_image = PIL_Image.open(BytesIO(response.content))\n",
        "        plt.figure(figsize=(6, 8))\n",
        "        plt.imshow(perfume_image)\n",
        "        plt.axis('off')\n",
        "        plt.title('Original Perfume Bottle')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Failed to load image: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading image: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouYUXlBAn5hT"
      },
      "outputs": [],
      "source": [
        "# First edit: Change perfume color to light purple\n",
        "first_edit_prompt = \"change the perfume color to a light purple\"\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\n",
        "                \"fileData\": {\n",
        "                    \"mimeType\": \"image/jpeg\",\n",
        "                    \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/perfume.jpg\"\n",
        "                }\n",
        "            },\n",
        "            {\"text\": first_edit_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(\"First edit: Changing perfume color to light purple...\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    parts = process_response(response)\n",
        "\n",
        "    # Save the generated image data for the next step\n",
        "    generated_image_data = None\n",
        "    for part in parts:\n",
        "        if 'inlineData' in part and 'data' in part['inlineData']:\n",
        "            generated_image_data = part['inlineData']['data']\n",
        "            break\n",
        "\n",
        "    print(\"First edit completed!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf1v48-qn5hT"
      },
      "outputs": [],
      "source": [
        "# Second edit: Add French text to the perfume bottle\n",
        "if 'generated_image_data' in locals() and generated_image_data:\n",
        "    second_edit_prompt = \"inscribe the word flowers in French on the perfume bottle in a delicate white cursive font\"\n",
        "\n",
        "    contents = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [\n",
        "                {\n",
        "                    \"inlineData\": {\n",
        "                        \"mimeType\": \"image/jpeg\",\n",
        "                        \"data\": generated_image_data\n",
        "                    }\n",
        "                },\n",
        "                {\"text\": second_edit_prompt}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    payload = create_request_payload(contents)\n",
        "\n",
        "    print(\"Second edit: Adding French text to the perfume bottle...\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    try:\n",
        "        response = send_gemini_request(payload)\n",
        "        process_response(response)\n",
        "        print(\"Second edit completed!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "else:\n",
        "    print(\"No image data from previous step. Please run the previous cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuviHbvln5hT"
      },
      "source": [
        "### Multiple Reference Images\n",
        "\n",
        "When editing images with Gemini 2.5 Flash Image, you can also supply multiple input images to create new ones. In this next example, you'll prompt Gemini with an image of a woman and a suitcase. You'll then ask Gemini to combine the objects from these images in order to create a new one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTpctngDn5hT"
      },
      "outputs": [],
      "source": [
        "# Display the reference images\n",
        "person_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/woman.jpg\"\n",
        "suitcase_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\"\n",
        "\n",
        "try:\n",
        "    # Load and display both images\n",
        "    person_response = requests.get(person_url)\n",
        "    suitcase_response = requests.get(suitcase_url)\n",
        "\n",
        "    if person_response.status_code == 200 and suitcase_response.status_code == 200:\n",
        "        person_image = PIL_Image.open(BytesIO(person_response.content))\n",
        "        suitcase_image = PIL_Image.open(BytesIO(suitcase_response.content))\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "        axes[0].imshow(person_image)\n",
        "        axes[0].set_title('Woman')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(suitcase_image)\n",
        "        axes[1].set_title('Suitcase')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Failed to load one or both reference images\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading images: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryGkPMZgn5hT"
      },
      "outputs": [],
      "source": [
        "# Generate new image combining multiple references\n",
        "multi_ref_prompt = \"Generate an image of the woman pulling the suitcase in an airport. Separately, write a short caption for this image that would be suitable for a social media post.\"\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\n",
        "                \"fileData\": {\n",
        "                    \"mimeType\": \"image/png\",\n",
        "                    \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/suitcase.png\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"fileData\": {\n",
        "                    \"mimeType\": \"image/jpeg\",\n",
        "                    \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/woman.jpg\"\n",
        "                }\n",
        "            },\n",
        "            {\"text\": multi_ref_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(\"Generating image combining multiple references...\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    process_response(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJc7TpKXn5hT"
      },
      "source": [
        "### Additional Image Editing Example (Croissant with Chocolate Drizzle)\n",
        "\n",
        "Let's implement the exact example from your REST API sample - adding chocolate drizzle to croissants with text overlay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAfTJPfNn5hT"
      },
      "outputs": [],
      "source": [
        "# Example from the original REST API sample\n",
        "croissant_edit_prompt = 'Add some chocolate drizzle to the croissants. Include text across the top of the image that says \"Made Fresh Daily\".'\n",
        "\n",
        "contents = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "            {\n",
        "                \"fileData\": {\n",
        "                    \"mimeType\": \"image/jpeg\",\n",
        "                    \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/croissant.jpeg\"\n",
        "                }\n",
        "            },\n",
        "            {\"text\": croissant_edit_prompt}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = create_request_payload(contents)\n",
        "\n",
        "print(\"Editing croissant image: Adding chocolate drizzle and text...\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "try:\n",
        "    response = send_gemini_request(payload)\n",
        "    process_response(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z69RyPPRn5hT"
      },
      "source": [
        "## Advanced REST API Examples\n",
        "\n",
        "### Using Raw cURL Commands (Alternative Approach)\n",
        "\n",
        "If you prefer to use direct cURL commands as shown in your original REST API example, here's how you can do it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xp21idLn5hT"
      },
      "outputs": [],
      "source": [
        "# Create a request.json file for cURL usage\n",
        "curl_request = {\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [\n",
        "                {\n",
        "                    \"fileData\": {\n",
        "                        \"mimeType\": \"image/jpeg\",\n",
        "                        \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/croissant.jpeg\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"text\": \"Add some chocolate drizzle to the croissants. Include text across the top of the image that says 'Made Fresh Daily'.\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"generation_config\": {\n",
        "        \"temperature\": 1,\n",
        "        \"max_output_tokens\": 32768,\n",
        "        \"response_modalities\": [\"TEXT\", \"IMAGE\"],\n",
        "        \"topP\": 0.95\n",
        "    },\n",
        "    \"safetySettings\": [\n",
        "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"OFF\"},\n",
        "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"OFF\"},\n",
        "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"OFF\"},\n",
        "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"OFF\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Save to request.json file\n",
        "with open('request.json', 'w') as f:\n",
        "    json.dump(curl_request, f, indent=2)\n",
        "\n",
        "print(\"Created request.json file for cURL usage\")\n",
        "print(\"You can now use the following cURL command:\")\n",
        "print(f\"\"\"curl \\\\\n",
        "-X POST \\\\\n",
        "-H \"Content-Type: application/json\" \\\\\n",
        "\"https://aiplatform.googleapis.com/v1/publishers/google/models/gemini-2.5-flash-image-preview:streamGenerateContent?key=YOUR_API_KEY\" \\\\\n",
        "-d '@request.json'\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIXQYUb9n5hT"
      },
      "source": [
        "### Error Handling and Best Practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roizJ4Fin5hU"
      },
      "outputs": [],
      "source": [
        "def robust_gemini_request(payload, max_retries=3, timeout=300):\n",
        "    \"\"\"Send request to Gemini API with retry logic and better error handling\"\"\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.post(BASE_URL, headers=headers, json=payload, timeout=timeout)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 429:  # Rate limit\n",
        "                print(f\"Rate limited. Waiting before retry {attempt + 1}/{max_retries}...\")\n",
        "                time.sleep(60)  # Wait 1 minute\n",
        "            elif response.status_code == 500:  # Server error\n",
        "                print(f\"Server error. Retrying {attempt + 1}/{max_retries}...\")\n",
        "                time.sleep(10)\n",
        "            else:\n",
        "                raise Exception(f\"API request failed: {response.status_code} - {response.text}\")\n",
        "\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f\"Request timeout. Retrying {attempt + 1}/{max_retries}...\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request exception: {e}. Retrying {attempt + 1}/{max_retries}...\")\n",
        "\n",
        "    raise Exception(f\"Failed after {max_retries} attempts\")\n",
        "\n",
        "# Example usage with robust error handling\n",
        "def generate_image_with_retry(prompt):\n",
        "    \"\"\"Generate image with robust error handling\"\"\"\n",
        "    contents = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [{\"text\": prompt}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    payload = create_request_payload(contents)\n",
        "\n",
        "    try:\n",
        "        response = robust_gemini_request(payload)\n",
        "        return process_response(response)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to generate image: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Robust error handling functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8PKperun5hU"
      },
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "This notebook has demonstrated how to use Gemini 2.5 Flash Image generation capabilities through REST API calls, covering:\n",
        "\n",
        "### Features Implemented:\n",
        "1. **Text-to-Image Generation**: Create images from text descriptions\n",
        "2. **Interleaved Text and Images**: Generate tutorials with mixed content\n",
        "3. **Subject Customization**: Style transfer and character consistency\n",
        "4. **Multi-turn Image Editing**: Conversational image editing\n",
        "5. **Multiple Reference Images**: Combine multiple images into new creations\n",
        "\n",
        "### Key Benefits of REST API Approach:\n",
        "- **Direct HTTP Control**: Full control over request/response handling\n",
        "- **Language Agnostic**: Can be used with any programming language\n",
        "- **Custom Error Handling**: Implement your own retry logic and error management\n",
        "- **Debugging**: Easy to inspect raw API requests and responses\n",
        "\n",
        "### Usage Notes:\n",
        "1. **API Key**: Replace `YOUR_API_KEY` with your actual Vertex AI API key\n",
        "2. **File Access**: For Google Cloud Storage files, use `fileUri` with `gs://` prefix\n",
        "3. **Local Files**: Use `inlineData` with base64 encoded image data\n",
        "4. **Safety Settings**: Adjust safety thresholds based on your requirements\n",
        "5. **Response Modalities**: Always include both `TEXT` and `IMAGE` for image generation\n",
        "\n",
        "### Best Practices:\n",
        "- Implement proper error handling and retry logic\n",
        "- Use appropriate timeouts for image generation requests\n",
        "- Handle rate limiting gracefully\n",
        "- Validate image file formats and sizes before sending\n",
        "- Store generated images appropriately for your use case\n",
        "\n",
        "### Further Exploration:\n",
        "- Experiment with different temperature and topP values\n",
        "- Try various prompt engineering techniques\n",
        "- Implement batch processing for multiple images\n",
        "- Integrate with your application's authentication flow\n",
        "- Explore advanced safety settings and content filtering\n",
        "\n",
        "This REST API approach provides the same powerful image generation capabilities as the SDK while giving you maximum flexibility and control over the integration."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}